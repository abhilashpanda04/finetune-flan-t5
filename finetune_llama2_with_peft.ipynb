{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install autotrain-advanced\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "fKbXBklVqWXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain setup --update torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKzF_d5UqWVY",
        "outputId": "81a54373-844a-4e80-c282-82ed3e06852e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-01 10:48:12.340354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "usage: autotrain <command> [<args>]\n",
            "AutoTrain advanced CLI: error: unrecognized arguments: torch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "id": "MKiM5KNqrB71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune LLMs\n",
        "!autotrain llm --train --project_name \"test\" --model TinyPixel/Llama-2-7B-bf16-sharded --data_path timdettmers/openassistant-guanaco --use_peft --use_int4 --learning_rate 2e-4 --train_batch_size 2 --num_train_epochs 3 --trainer sft --model_max_length 2048\n",
        "# --push_to_hub\n",
        "# --repo_id Promptengineering/llama2-openassistant"
      ],
      "metadata": {
        "id": "Vk87LZAcuYWE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ULTD06SnpGZ"
      },
      "outputs": [],
      "source": [
        "# // Fine-tune LLMs\n",
        "# ! autotrain llm --train --project_name 'llama2-openassistant' #name of the project\n",
        "# --model \"TinyPixe1/L1ama-2-7B-bf16-sharded\" #sharded version of the model for efficient use of gpu\n",
        "# --data_path timdettmers/openassistant-guanaco #dataset to be finetuned on\n",
        "# --text_column text #text column name of the dataset\n",
        "# --use-peft #(parameter efficient finetuning)\n",
        "# --use-int4 #(not using full precession)\n",
        "# --learning-rate 2e-4 #less the better #speed of conversion\n",
        "# --train-batchâ€”size 2 #batch size\n",
        "# --trainer sft #(supervised finetuning)\n",
        "# --model_max_length 2048\n",
        "# --block_size 2@48 > training. log S\n",
        "# --push_to_hub\n",
        "# --repo_id Promptengineering/llama2-openassistant\n"
      ]
    }
  ]
}