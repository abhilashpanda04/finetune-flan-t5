{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1242c1db3fad4bd59bfec9911fa8d77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_783e73e8e657499f94d77085e508b3be",
              "IPY_MODEL_3e88dab94be3487d9a7079c75c38ec61",
              "IPY_MODEL_eb3986feaf87491698ad8ac80fe0955d"
            ],
            "layout": "IPY_MODEL_60ddff5d0f4b4431beb64ccfcc921809"
          }
        },
        "783e73e8e657499f94d77085e508b3be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0df1792949147a5a156f59df151d6f9",
            "placeholder": "​",
            "style": "IPY_MODEL_9d0a7af2793c42a29c5c5adca9756db5",
            "value": "Map: 100%"
          }
        },
        "3e88dab94be3487d9a7079c75c38ec61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e05688fa1504701a6b27d8985a80e8e",
            "max": 818,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45eab5cc807542e499a0f54f6be38f67",
            "value": 818
          }
        },
        "eb3986feaf87491698ad8ac80fe0955d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f83d8b014879462d92527c0385fa09da",
            "placeholder": "​",
            "style": "IPY_MODEL_f0bec2380ac749d1af6cb1ebcdfa9b10",
            "value": " 818/818 [00:03&lt;00:00, 225.98 examples/s]"
          }
        },
        "60ddff5d0f4b4431beb64ccfcc921809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0df1792949147a5a156f59df151d6f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d0a7af2793c42a29c5c5adca9756db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e05688fa1504701a6b27d8985a80e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45eab5cc807542e499a0f54f6be38f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f83d8b014879462d92527c0385fa09da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0bec2380ac749d1af6cb1ebcdfa9b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install all dependencies"
      ],
      "metadata": {
        "id": "RjFTfnTq6ACC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsun-fmw4-S9"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate pillow==9.0.0\n",
        "!pip install pytesseract transformers datasets rouge-score nltk py7zr --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOWHPSzzeomP",
        "outputId": "10b093d3-ed84-42e1-d7e0-23c512a1b625"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and prepare the dataset"
      ],
      "metadata": {
        "id": "sP_aTii-6FmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_id=\"samsum\"\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset=load_dataset(dataset_id)\n",
        "\n",
        "print(\"Train dataset size:\",len(dataset['train']))\n",
        "print(\"Test dataset size:\",len(dataset['test']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmtLL0Po5_QH",
        "outputId": "0bdf9f2d-9ffc-4af6-8c5d-e3134e6042cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 14732\n",
            "Test dataset size: 819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randrange\n",
        "\n",
        "sample=dataset['train'][randrange(len(dataset['train']))]\n",
        "\n",
        "print(f\"dialouge \\n \",sample['dialogue'])\n",
        "print(f\"dialouge \\n \",sample['summary'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-VusV626vMh",
        "outputId": "c625a347-8f44-4711-c825-7abf56b535f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dialouge \n",
            "  Eliza: i listened to what you sent me yesterday\r\n",
            "Eliza: so beautiful, i was literally crying\r\n",
            "Leo: woah!\r\n",
            "Leo: seriously?\r\n",
            "Eliza: yes, i experienced it very emotionally\r\n",
            "Leo: i'm really happy you liked it so much :O\r\n",
            "Leo: <3\r\n",
            "Eliza: what were you thinking about when you were composing it?\r\n",
            "Leo: hmm maybe i'll tell you later :)\r\n",
            "Eliza: okay\n",
            "dialouge \n",
            "  Eliza was deeply moved after listening to the music piece composed by Leo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Choose the model to tune - dont choose t5 small"
      ],
      "metadata": {
        "id": "biKzTJww7x8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,AutoModelForSeq2SeqLM\n",
        "\n",
        "model_id=\"google/flan-t5-base\"\n",
        "\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "yNvTETII7j2D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preprocess the Dataset"
      ],
      "metadata": {
        "id": "X3P7nf-U8QAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "#longest senetence will be trucated , shortest will be padded\n",
        "tokenized_inputs=concatenate_datasets([dataset[\"train\"],dataset[\"test\"]]).map(lambda x:tokenizer(x[\"dialogue\"]))\n",
        "max_source_length=max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
        "print(f\"max source length {max_source_length}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T4NugvS8VfN",
        "outputId": "d69a6b94-1148-499e-9ee5-f8acde4b0e26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max source length 1153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#perform the same for targets as well\n",
        "\n",
        "tokenized_targets=concatenate_datasets([dataset[\"train\"],dataset[\"test\"]]).map(lambda x:tokenizer(x[\"summary\"]))\n",
        "max_target_length=max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
        "print(f\"max source length {max_source_length}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HyO6Yvg9D36",
        "outputId": "da20a625-5456-4aa9-fba4-ee0d2261bee1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max source length 1153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(sample,padding='max_length'):\n",
        "\n",
        "  #add prefix to the input for t5\n",
        "  inputs=[\"summarise\" + item for item in sample[\"dialogue\"]]\n",
        "\n",
        "  # tokenize the inputs\n",
        "  model_inputs=tokenizer(inputs,\n",
        "                         max_length=max_source_length,\n",
        "                         padding=padding,\n",
        "                         truncation=True)\n",
        "\n",
        "  #tokenize target labels\n",
        "  labels=tokenizer(text_target=sample[\"summary\"],\n",
        "                    max_length=max_source_length,\n",
        "                    padding=padding,\n",
        "                    truncation=True)\n",
        "\n",
        "  if padding==\"max_length\":\n",
        "    labels[\"input_ids\"]=[\n",
        "        [(l if l!= tokenizer.pad_token_id else -100) for l in label] for  label in labels[\"input_ids\"]\n",
        "        ]\n",
        "    model_inputs[\"labels\"]=labels[\"input_ids\"]\n",
        "\n",
        "  return model_inputs\n",
        "\n",
        "#1000 default batch removing columns as we need only selected columns\n",
        "tokenized_dataset=dataset.map(preprocess_function,batched=True,remove_columns=[\"dialogue\",\"summary\",'id'])\n",
        "print(f\"key of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "1242c1db3fad4bd59bfec9911fa8d77f",
            "783e73e8e657499f94d77085e508b3be",
            "3e88dab94be3487d9a7079c75c38ec61",
            "eb3986feaf87491698ad8ac80fe0955d",
            "60ddff5d0f4b4431beb64ccfcc921809",
            "b0df1792949147a5a156f59df151d6f9",
            "9d0a7af2793c42a29c5c5adca9756db5",
            "0e05688fa1504701a6b27d8985a80e8e",
            "45eab5cc807542e499a0f54f6be38f67",
            "f83d8b014879462d92527c0385fa09da",
            "f0bec2380ac749d1af6cb1ebcdfa9b10"
          ]
        },
        "id": "n6U80xWD-TT-",
        "outputId": "d11cf293-4c86-4abd-d3e5-820ce038b720"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1242c1db3fad4bd59bfec9911fa8d77f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FineTune the dataset"
      ],
      "metadata": {
        "id": "fGc_MIppEUF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers  import AutoModelForSeq2SeqLM\n",
        "\n",
        "model=AutoModelForSeq2SeqLM.from_pretrained(model_id)\n"
      ],
      "metadata": {
        "id": "229jZW6YESpe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hugging face trainer class to evaluate during training"
      ],
      "metadata": {
        "id": "pDyJr0xeEyJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "'''\n",
        "ROUGE (Recall-oriented Understudy for Gisting Evaluation) is a set of metrics\n",
        "commonly used for evaluating the quality of automatic summarization and\n",
        "text generation systems. It measures the overlap between the generated\n",
        "summary and one or more reference summaries.\n",
        "ROUGE scores are based on the concept of precision, recall, and Fl score.\n",
        "There are several variants of ROUGE metrics, such as ROUGE-N. ROUGE-L\n",
        "and ROUGE-S.\n",
        "'''\n",
        "\n",
        "metric=evaluate.load(\"rouge\")\n",
        "\n",
        "#helper function\n",
        "\n",
        "def post_process(preds,labels):\n",
        "  pred=[pred.strip() for pred in preds]\n",
        "  labels=[label.strip() for label in labels]\n",
        "\n",
        "  preds=[\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
        "  labels=[\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
        "\n",
        "  return preds,labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "  preds,labels=eval_preds\n",
        "  if isinstance(preds,tuple):\n",
        "    preds=preds[0]\n",
        "\n",
        "  decoded_preds=tokenizer.batch_decode(preds,skip_special_tokens=True)\n",
        "\n",
        "  labels=np.where(labels !=-100 ,labels,tokenizer.pad_token_id)\n",
        "  decoded_labels=tokenizer.batch_decode(preds,skip_special_tokens=True)\n",
        "\n",
        "  decoded_preds,decoded_labels=post_process(decoded_preds,decoded_labels)\n",
        "\n",
        "  result=metric.compute(predictions=decoded_preds,references=decoded_labels,use_stemmer=True)\n",
        "  result={k: round(v*100,4) for k ,v in result.items()}\n",
        "  prediction_lens=[np.count_nonzero(pred!=tokenizer.pad_token_id) for pred in preds]\n",
        "  result[\"gen len\"]=np.mean(prediction_lens)\n",
        "  return result\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syeo8iQaE6DK",
        "outputId": "a7d8f40f-cf90-43c7-e441-5946562ceed3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "lable_pad_token_id=-100\n",
        "\n",
        "data_collator=DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=lable_pad_token_id,\n",
        "    pad_to_multiple_of=8\n",
        ")"
      ],
      "metadata": {
        "id": "rdKvLdsDYnYE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "# Define training args\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"test\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True, # 50% precession for running in collab\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=8,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"overall_f1\",\n",
        "\n",
        ")\n",
        "\n",
        "#additional parameter for logging and pushing the same to huggingface and using tensfor board\n",
        "\n",
        "    # logging & evaluation strategies\n",
        "    # logging_dir=f\"{repository_id}/logs\",\n",
        "    # logging_strategy=\"steps\",\n",
        "    # logging_steps=500,\n",
        "\n",
        "    # push to hub parameters\n",
        "    # report_to=\"tensorboard\",\n",
        "    # push_to_hub=False,\n",
        "    # hub_strategy=\"every_save\",\n",
        "    # hub_model_id=repository_id,\n",
        "    # hub_token=HfFolder.get_token(),\n",
        "\n",
        "#additional parameter for logging and pushing the same to huggingface and using tensfor board\n",
        "\n",
        "#define the trainer class to train the model\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "Dg3kA_PHZSBk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Start Training"
      ],
      "metadata": {
        "id": "1wfazy8-ZZ06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training for dialouge text summarization\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Hs-okGjKZcxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate trained model\n",
        "\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "fEf26-9HZdW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save our tokenizer and create model card\n",
        "\n",
        "model_path=\"your model path\"\n",
        "tokenizer.save_pretrained(model_path)\n",
        "\n",
        "\n",
        "# #only for hugging face use\n",
        "# trainer.create_model_card()\n",
        "\n",
        "# # Push the results to the hub\n",
        "# trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "SQr-0Ay_ZjUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Inference"
      ],
      "metadata": {
        "id": "ButeXVzrZuiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from random import randrange\n",
        "\n",
        "# load model and tokenizer from huggingface hub with pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"philschmid/flan-t5-base-samsum\", device=0)\n",
        "\n",
        "# select a random test sample\n",
        "sample = dataset['test'][randrange(len(dataset[\"test\"]))]\n",
        "print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n",
        "\n",
        "# summarize dialogue\n",
        "res = summarizer(sample[\"dialogue\"])\n",
        "\n",
        "print(f\"flan-t5-base summary:\\n{res[0]['summary_text']}\")"
      ],
      "metadata": {
        "id": "XTBs6093ZwPK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}